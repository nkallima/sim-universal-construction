<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>The Synch framework: threadtools.h File Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="logo_synch.png"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">The Synch framework
   &#160;<span id="projectnumber">v3.1.3</span>
   </div>
   <div id="projectbrief">An open-source framework for concurrent data-structures and benchmarks</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_bba3cddd56565a95b77b098fd409d0ab.html">libconcurrent</a></li><li class="navelem"><a class="el" href="dir_3b0504cce330a6e867091f76f8160def.html">includes</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#define-members">Macros</a> &#124;
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle">
<div class="title">threadtools.h File Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>This file exposes a simple API for handling both posix and user-level threads. This API provides functionality for creating new threads (both posix and user-level), functionality for setting affinities, functionality for yielding the processor, etc. Examples of usage could be found in almost all the provided benchmarks under the benchmarks directory.  
<a href="#details">More...</a></p>

<p><a href="threadtools_8h_source.html">Go to the source code of this file.</a></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="define-members"></a>
Macros</h2></td></tr>
<tr class="memitem:a9644b82322ca074853e0fb757a5ef56a"><td class="memItemLeft" align="right" valign="top">#define&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="threadtools_8h.html#a9644b82322ca074853e0fb757a5ef56a">SYNCH_DONT_USE_UTHREADS</a>&#160;&#160;&#160;1</td></tr>
<tr class="separator:a9644b82322ca074853e0fb757a5ef56a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af0d8dd48e058689775f0f7dcd2900c26"><td class="memItemLeft" align="right" valign="top">#define&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="threadtools_8h.html#af0d8dd48e058689775f0f7dcd2900c26">SYNCH_THREAD_PLACEMENT_FLAT</a>&#160;&#160;&#160;0x1</td></tr>
<tr class="memdesc:af0d8dd48e058689775f0f7dcd2900c26"><td class="mdescLeft">&#160;</td><td class="mdescRight">Threads are distributed in a round-robin fashion across all processing cores.  <a href="threadtools_8h.html#af0d8dd48e058689775f0f7dcd2900c26">More...</a><br /></td></tr>
<tr class="separator:af0d8dd48e058689775f0f7dcd2900c26"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a733f4eb16a537483b356be0f5a62589f"><td class="memItemLeft" align="right" valign="top">#define&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="threadtools_8h.html#a733f4eb16a537483b356be0f5a62589f">SYNCH_THREAD_PLACEMENT_NUMA_SPARSE</a>&#160;&#160;&#160;0x2</td></tr>
<tr class="memdesc:a733f4eb16a537483b356be0f5a62589f"><td class="mdescLeft">&#160;</td><td class="mdescRight">It optimizes thread placement for systems with Non-Uniform Memory Access (NUMA) by spreading threads sparsely across NUMA nodes, potentially improving memory bandwidth and improving cache utilization.  <a href="threadtools_8h.html#a733f4eb16a537483b356be0f5a62589f">More...</a><br /></td></tr>
<tr class="separator:a733f4eb16a537483b356be0f5a62589f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a094e4b89c25ed9c25629d67f96c61ce0"><td class="memItemLeft" align="right" valign="top">#define&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="threadtools_8h.html#a094e4b89c25ed9c25629d67f96c61ce0">SYNCH_THREAD_PLACEMENT_NUMA_DENSE</a>&#160;&#160;&#160;0x3</td></tr>
<tr class="memdesc:a094e4b89c25ed9c25629d67f96c61ce0"><td class="mdescLeft">&#160;</td><td class="mdescRight">It places threads within the smallest number of NUMA nodes before spreading them to other nodes, which can improve memory locality and may reduce contention on shared variables.  <a href="threadtools_8h.html#a094e4b89c25ed9c25629d67f96c61ce0">More...</a><br /></td></tr>
<tr class="separator:a094e4b89c25ed9c25629d67f96c61ce0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9703f3c4fbe262393fcd459767db52dd"><td class="memItemLeft" align="right" valign="top">#define&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="threadtools_8h.html#a9703f3c4fbe262393fcd459767db52dd">SYNCH_THREAD_PLACEMENT_NUMA_SPARSE_SMT_PREFER</a>&#160;&#160;&#160;0x4</td></tr>
<tr class="memdesc:a9703f3c4fbe262393fcd459767db52dd"><td class="mdescLeft">&#160;</td><td class="mdescRight">Similar to <code>SYNCH_THREAD_PLACEMENT_NUMA_DENSE</code>, but with a preference for utilizing Simultaneous Multithreading (SMT) capabilities within NUMA nodes to maximize processing efficiency.  <a href="threadtools_8h.html#a9703f3c4fbe262393fcd459767db52dd">More...</a><br /></td></tr>
<tr class="separator:a9703f3c4fbe262393fcd459767db52dd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1f00f4ea0cf4fb03226d808c20ace2bf"><td class="memItemLeft" align="right" valign="top">#define&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="threadtools_8h.html#a1f00f4ea0cf4fb03226d808c20ace2bf">SYNCH_THREAD_PLACEMENT_NUMA_DENSE_SMT_PREFER</a>&#160;&#160;&#160;0x5</td></tr>
<tr class="memdesc:a1f00f4ea0cf4fb03226d808c20ace2bf"><td class="mdescLeft">&#160;</td><td class="mdescRight">It combines the sparse distribution strategy across NUMA nodes with a preference for SMT. This policy spreads threads across NUMA nodes to avoid contention, while preferring to fill SMT slots within each core before moving to the next. It aims to strike a balance between improving memory bandwidth and leveraging SMT for higher processing efficiency and reduced contention on shared variables.  <a href="threadtools_8h.html#a1f00f4ea0cf4fb03226d808c20ace2bf">More...</a><br /></td></tr>
<tr class="separator:a1f00f4ea0cf4fb03226d808c20ace2bf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a50ab85f3af1acb14671d6589754538a3"><td class="memItemLeft" align="right" valign="top">#define&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="threadtools_8h.html#a50ab85f3af1acb14671d6589754538a3">SYNCH_THREAD_PLACEMENT_POLICY_MAX</a>&#160;&#160;&#160;<a class="el" href="threadtools_8h.html#a1f00f4ea0cf4fb03226d808c20ace2bf">SYNCH_THREAD_PLACEMENT_NUMA_DENSE_SMT_PREFER</a></td></tr>
<tr class="memdesc:a50ab85f3af1acb14671d6589754538a3"><td class="mdescLeft">&#160;</td><td class="mdescRight">The maximum defined supported thread placement policy that is available.  <a href="threadtools_8h.html#a50ab85f3af1acb14671d6589754538a3">More...</a><br /></td></tr>
<tr class="separator:a50ab85f3af1acb14671d6589754538a3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5d02ff01afd8666f9354ffa5b04e157f"><td class="memItemLeft" align="right" valign="top">#define&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="threadtools_8h.html#a5d02ff01afd8666f9354ffa5b04e157f">SYNCH_THREAD_PLACEMENT_DEFAULT</a>&#160;&#160;&#160;<a class="el" href="threadtools_8h.html#a9703f3c4fbe262393fcd459767db52dd">SYNCH_THREAD_PLACEMENT_NUMA_SPARSE_SMT_PREFER</a></td></tr>
<tr class="memdesc:a5d02ff01afd8666f9354ffa5b04e157f"><td class="mdescLeft">&#160;</td><td class="mdescRight">By default the thread placement policy is se to <code>SYNCH_THREAD_PLACEMENT_DEFAULT</code>. Currently, <code>SYNCH_THREAD_PLACEMENT_DEFAULT</code> is equal to <code>SYNCH_THREAD_PLACEMENT_NUMA_SPARSE_SMT_PREFER</code>.  <a href="threadtools_8h.html#a5d02ff01afd8666f9354ffa5b04e157f">More...</a><br /></td></tr>
<tr class="separator:a5d02ff01afd8666f9354ffa5b04e157f"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:ab271ce770f682a143aad0a6d671a407c"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="threadtools_8h.html#ab271ce770f682a143aad0a6d671a407c">synchStartThreadsN</a> (uint32_t nthreads, void *(*func)(void *), uint32_t uthreads)</td></tr>
<tr class="memdesc:ab271ce770f682a143aad0a6d671a407c"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function creates nthreads posix threads, where each posix thread executes uthreads user-level threads (fibers). Thus, the total amount of threads and fibers is nthreads * uthreads. Each of the created threads executes the func function, the function has as an argument the id of the created thread, which is a unique integer in {0, ..., nthreads * uthreads - 1}. In case, the user does not want to create any fiber, uthreads should be equal to SYNCH_DONT_USE_UTHREADS.  <a href="threadtools_8h.html#ab271ce770f682a143aad0a6d671a407c">More...</a><br /></td></tr>
<tr class="separator:ab271ce770f682a143aad0a6d671a407c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af4308af25d549ba165c86987cecedd93"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="threadtools_8h.html#af4308af25d549ba165c86987cecedd93">synchJoinThreadsN</a> (uint32_t nthreads)</td></tr>
<tr class="memdesc:af4308af25d549ba165c86987cecedd93"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function returns whenever all the created posix threads and fibers spawned by StartThreadsN have completed the execution.  <a href="threadtools_8h.html#af4308af25d549ba165c86987cecedd93">More...</a><br /></td></tr>
<tr class="separator:af4308af25d549ba165c86987cecedd93"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5be8ef256e5d61a99ec322fd74ef43ad"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="threadtools_8h.html#a5be8ef256e5d61a99ec322fd74ef43ad">synchSetThreadPlacementPolicy</a> (uint32_t policy)</td></tr>
<tr class="memdesc:a5be8ef256e5d61a99ec322fd74ef43ad"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function sets the default placement policy of threads in machine's processors. The thread placement policy could set any of the following:  <a href="threadtools_8h.html#a5be8ef256e5d61a99ec322fd74ef43ad">More...</a><br /></td></tr>
<tr class="separator:a5be8ef256e5d61a99ec322fd74ef43ad"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a12ae650a6b6b149c2575391e1f12efc5"><td class="memItemLeft" align="right" valign="top">uint32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="threadtools_8h.html#a12ae650a6b6b149c2575391e1f12efc5">synchGetThreadPlacementPolicy</a> (void)</td></tr>
<tr class="memdesc:a12ae650a6b6b149c2575391e1f12efc5"><td class="mdescLeft">&#160;</td><td class="mdescRight">Retrieves the current thread placement policy for the machine's processors. This function returns the policy setting that determines how threads are distributed across the processing cores of the machine. The possible return values correspond to the thread placement policies that could be returned are the following:  <a href="threadtools_8h.html#a12ae650a6b6b149c2575391e1f12efc5">More...</a><br /></td></tr>
<tr class="separator:a12ae650a6b6b149c2575391e1f12efc5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3de1163861672aea5b005f27534c6392"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="threadtools_8h.html#a3de1163861672aea5b005f27534c6392">synchThreadPin</a> (int32_t cpu_id)</td></tr>
<tr class="memdesc:a3de1163861672aea5b005f27534c6392"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function sets the CPU affinity of the running thread to cpu_id, where cpu_id should be a unique integer in {0, ..., N-1}, where N is the amount of available processing cores.  <a href="threadtools_8h.html#a3de1163861672aea5b005f27534c6392">More...</a><br /></td></tr>
<tr class="separator:a3de1163861672aea5b005f27534c6392"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af83962f77edd1b750d54c264399ed3c2"><td class="memItemLeft" align="right" valign="top">uint32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="threadtools_8h.html#af83962f77edd1b750d54c264399ed3c2">synchPreferredNumaNodeOfThread</a> (uint32_t pid)</td></tr>
<tr class="separator:af83962f77edd1b750d54c264399ed3c2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1d09340006207505a5d09fd62f1db266"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="threadtools_8h.html#a1d09340006207505a5d09fd62f1db266">synchGetThreadId</a> (void)</td></tr>
<tr class="memdesc:a1d09340006207505a5d09fd62f1db266"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function returns the id of the running thread (posix or fiber). More specifically, it returns a unique integer in {0, ..., N-1}, where N is the amount of the running threads. For example, if 3 Posix threads are running, and 4 fiber threads are running inside each Posix thread, this function will return an integer in the interval of {0, ...., 11}.  <a href="threadtools_8h.html#a1d09340006207505a5d09fd62f1db266">More...</a><br /></td></tr>
<tr class="separator:a1d09340006207505a5d09fd62f1db266"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a578692aef02cdeda1bdede23934faa2c"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="threadtools_8h.html#a578692aef02cdeda1bdede23934faa2c">synchGetPreferredNumaNode</a> (void)</td></tr>
<tr class="separator:a578692aef02cdeda1bdede23934faa2c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:add65bdc6f8950666dbe2e17fbc850b66"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="threadtools_8h.html#add65bdc6f8950666dbe2e17fbc850b66">synchGetPosixThreadId</a> (void)</td></tr>
<tr class="memdesc:add65bdc6f8950666dbe2e17fbc850b66"><td class="mdescLeft">&#160;</td><td class="mdescRight">This fuction returns the id of the current posix thread. This function should return an identical value for any fiber running in the same posix thread.  <a href="threadtools_8h.html#add65bdc6f8950666dbe2e17fbc850b66">More...</a><br /></td></tr>
<tr class="separator:add65bdc6f8950666dbe2e17fbc850b66"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa340fc67201baff160e5167b063cb02e"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="threadtools_8h.html#aa340fc67201baff160e5167b063cb02e">synchGetPreferredCore</a> (void)</td></tr>
<tr class="memdesc:aa340fc67201baff160e5167b063cb02e"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function returns the core-id of the current posix thread or fiber. The core-id is a unique integer in {0, ..., N-1}, where N is the amount of available processing cores.  <a href="threadtools_8h.html#aa340fc67201baff160e5167b063cb02e">More...</a><br /></td></tr>
<tr class="separator:aa340fc67201baff160e5167b063cb02e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4f83100fe2cf41ab6047cd8b5fce517e"><td class="memItemLeft" align="right" valign="top">uint32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="threadtools_8h.html#a4f83100fe2cf41ab6047cd8b5fce517e">synchPreferredCoreOfThread</a> (uint32_t pid)</td></tr>
<tr class="memdesc:a4f83100fe2cf41ab6047cd8b5fce517e"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function returns the core-id of the posix thread or fiber with id equal to pid. The core-id is a unique integer in {0, ..., N-1}, where N is the amount of available processing cores.  <a href="threadtools_8h.html#a4f83100fe2cf41ab6047cd8b5fce517e">More...</a><br /></td></tr>
<tr class="separator:a4f83100fe2cf41ab6047cd8b5fce517e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a02d99105ff01612887e1a97527006a82"><td class="memItemLeft" align="right" valign="top">uint32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="threadtools_8h.html#a02d99105ff01612887e1a97527006a82">synchGetNCores</a> (void)</td></tr>
<tr class="memdesc:a02d99105ff01612887e1a97527006a82"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function returns the number of system's processing cores.  <a href="threadtools_8h.html#a02d99105ff01612887e1a97527006a82">More...</a><br /></td></tr>
<tr class="separator:a02d99105ff01612887e1a97527006a82"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8e0619760c0a532a8b262fb529486a63"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="threadtools_8h.html#a8e0619760c0a532a8b262fb529486a63">synchResched</a> (void)</td></tr>
<tr class="memdesc:a8e0619760c0a532a8b262fb529486a63"><td class="mdescLeft">&#160;</td><td class="mdescRight">In case that this function is called by a posix thread, it hints OS to give the CPU to some other thread. In case that this function is called by a fiber, it gives the CPU control to the next fiber (if any) running in the same posix thread.  <a href="threadtools_8h.html#a8e0619760c0a532a8b262fb529486a63">More...</a><br /></td></tr>
<tr class="separator:a8e0619760c0a532a8b262fb529486a63"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1100af5666ae597a80ec8aeb6e8e7a92"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="threadtools_8h.html#a1100af5666ae597a80ec8aeb6e8e7a92">synchIsSystemOversubscribed</a> (void)</td></tr>
<tr class="memdesc:a1100af5666ae597a80ec8aeb6e8e7a92"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function returns true if the number of spawned threads is greater than the number of system's available processing cores; otherwise, this function returns false.  <a href="threadtools_8h.html#a1100af5666ae597a80ec8aeb6e8e7a92">More...</a><br /></td></tr>
<tr class="separator:a1100af5666ae597a80ec8aeb6e8e7a92"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>This file exposes a simple API for handling both posix and user-level threads. This API provides functionality for creating new threads (both posix and user-level), functionality for setting affinities, functionality for yielding the processor, etc. Examples of usage could be found in almost all the provided benchmarks under the benchmarks directory. </p>
</div><h2 class="groupheader">Macro Definition Documentation</h2>
<a id="a9644b82322ca074853e0fb757a5ef56a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9644b82322ca074853e0fb757a5ef56a">&#9670;&nbsp;</a></span>SYNCH_DONT_USE_UTHREADS</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">#define SYNCH_DONT_USE_UTHREADS&#160;&#160;&#160;1</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="af0d8dd48e058689775f0f7dcd2900c26"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af0d8dd48e058689775f0f7dcd2900c26">&#9670;&nbsp;</a></span>SYNCH_THREAD_PLACEMENT_FLAT</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">#define SYNCH_THREAD_PLACEMENT_FLAT&#160;&#160;&#160;0x1</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Threads are distributed in a round-robin fashion across all processing cores. </p>

</div>
</div>
<a id="a733f4eb16a537483b356be0f5a62589f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a733f4eb16a537483b356be0f5a62589f">&#9670;&nbsp;</a></span>SYNCH_THREAD_PLACEMENT_NUMA_SPARSE</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">#define SYNCH_THREAD_PLACEMENT_NUMA_SPARSE&#160;&#160;&#160;0x2</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>It optimizes thread placement for systems with Non-Uniform Memory Access (NUMA) by spreading threads sparsely across NUMA nodes, potentially improving memory bandwidth and improving cache utilization. </p>

</div>
</div>
<a id="a094e4b89c25ed9c25629d67f96c61ce0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a094e4b89c25ed9c25629d67f96c61ce0">&#9670;&nbsp;</a></span>SYNCH_THREAD_PLACEMENT_NUMA_DENSE</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">#define SYNCH_THREAD_PLACEMENT_NUMA_DENSE&#160;&#160;&#160;0x3</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>It places threads within the smallest number of NUMA nodes before spreading them to other nodes, which can improve memory locality and may reduce contention on shared variables. </p>

</div>
</div>
<a id="a9703f3c4fbe262393fcd459767db52dd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9703f3c4fbe262393fcd459767db52dd">&#9670;&nbsp;</a></span>SYNCH_THREAD_PLACEMENT_NUMA_SPARSE_SMT_PREFER</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">#define SYNCH_THREAD_PLACEMENT_NUMA_SPARSE_SMT_PREFER&#160;&#160;&#160;0x4</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Similar to <code>SYNCH_THREAD_PLACEMENT_NUMA_DENSE</code>, but with a preference for utilizing Simultaneous Multithreading (SMT) capabilities within NUMA nodes to maximize processing efficiency. </p>

</div>
</div>
<a id="a1f00f4ea0cf4fb03226d808c20ace2bf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1f00f4ea0cf4fb03226d808c20ace2bf">&#9670;&nbsp;</a></span>SYNCH_THREAD_PLACEMENT_NUMA_DENSE_SMT_PREFER</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">#define SYNCH_THREAD_PLACEMENT_NUMA_DENSE_SMT_PREFER&#160;&#160;&#160;0x5</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>It combines the sparse distribution strategy across NUMA nodes with a preference for SMT. This policy spreads threads across NUMA nodes to avoid contention, while preferring to fill SMT slots within each core before moving to the next. It aims to strike a balance between improving memory bandwidth and leveraging SMT for higher processing efficiency and reduced contention on shared variables. </p>

</div>
</div>
<a id="a50ab85f3af1acb14671d6589754538a3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a50ab85f3af1acb14671d6589754538a3">&#9670;&nbsp;</a></span>SYNCH_THREAD_PLACEMENT_POLICY_MAX</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">#define SYNCH_THREAD_PLACEMENT_POLICY_MAX&#160;&#160;&#160;<a class="el" href="threadtools_8h.html#a1f00f4ea0cf4fb03226d808c20ace2bf">SYNCH_THREAD_PLACEMENT_NUMA_DENSE_SMT_PREFER</a></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The maximum defined supported thread placement policy that is available. </p>

</div>
</div>
<a id="a5d02ff01afd8666f9354ffa5b04e157f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5d02ff01afd8666f9354ffa5b04e157f">&#9670;&nbsp;</a></span>SYNCH_THREAD_PLACEMENT_DEFAULT</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">#define SYNCH_THREAD_PLACEMENT_DEFAULT&#160;&#160;&#160;<a class="el" href="threadtools_8h.html#a9703f3c4fbe262393fcd459767db52dd">SYNCH_THREAD_PLACEMENT_NUMA_SPARSE_SMT_PREFER</a></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>By default the thread placement policy is se to <code>SYNCH_THREAD_PLACEMENT_DEFAULT</code>. Currently, <code>SYNCH_THREAD_PLACEMENT_DEFAULT</code> is equal to <code>SYNCH_THREAD_PLACEMENT_NUMA_SPARSE_SMT_PREFER</code>. </p>

</div>
</div>
<h2 class="groupheader">Function Documentation</h2>
<a id="ab271ce770f682a143aad0a6d671a407c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab271ce770f682a143aad0a6d671a407c">&#9670;&nbsp;</a></span>synchStartThreadsN()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int synchStartThreadsN </td>
          <td>(</td>
          <td class="paramtype">uint32_t&#160;</td>
          <td class="paramname"><em>nthreads</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *(*)(void *)&#160;</td>
          <td class="paramname"><em>func</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">uint32_t&#160;</td>
          <td class="paramname"><em>uthreads</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function creates nthreads posix threads, where each posix thread executes uthreads user-level threads (fibers). Thus, the total amount of threads and fibers is nthreads * uthreads. Each of the created threads executes the func function, the function has as an argument the id of the created thread, which is a unique integer in {0, ..., nthreads * uthreads - 1}. In case, the user does not want to create any fiber, uthreads should be equal to SYNCH_DONT_USE_UTHREADS. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">nthreads</td><td>The number of posix threads. </td></tr>
    <tr><td class="paramname">func</td><td>A function that each fiber and posix thread should execute. This function has as a single argument the unique id of the thread. </td></tr>
    <tr><td class="paramname">uthreads</td><td>The number of fibers that each posix thread should execute. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="af4308af25d549ba165c86987cecedd93"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af4308af25d549ba165c86987cecedd93">&#9670;&nbsp;</a></span>synchJoinThreadsN()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void synchJoinThreadsN </td>
          <td>(</td>
          <td class="paramtype">uint32_t&#160;</td>
          <td class="paramname"><em>nthreads</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function returns whenever all the created posix threads and fibers spawned by StartThreadsN have completed the execution. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">nthreads</td><td>The number of posix threads that StartThreadsN spawned. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a5be8ef256e5d61a99ec322fd74ef43ad"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5be8ef256e5d61a99ec322fd74ef43ad">&#9670;&nbsp;</a></span>synchSetThreadPlacementPolicy()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void synchSetThreadPlacementPolicy </td>
          <td>(</td>
          <td class="paramtype">uint32_t&#160;</td>
          <td class="paramname"><em>policy</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function sets the default placement policy of threads in machine's processors. The thread placement policy could set any of the following: </p>
<ul>
<li><code>SYNCH_THREAD_PLACEMENT_FLAT</code>: Threads are distributed in a round-robin fashion across all processing cores.</li>
<li><code>SYNCH_THREAD_PLACEMENT_NUMA_SPARSE</code>: Optimizes thread placement for systems with Non-Uniform Memory Access (NUMA) by spreading threads sparsely across NUMA nodes, potentially improving memory bandwidth and improving cache utilization.</li>
<li><code>SYNCH_THREAD_PLACEMENT_NUMA_DENSE</code>: Places threads within the smallest number of NUMA nodes before spreading them to other nodes, which can improve memory locality and may reduce contention on shared variables.</li>
<li><code>SYNCH_THREAD_PLACEMENT_NUMA_DENSE_SMT_PREFER</code>: Similar to <code>SYNCH_THREAD_PLACEMENT_NUMA_DENSE</code>, but with a preference for utilizing Simultaneous Multithreading (SMT) capabilities within NUMA nodes to maximize processing efficiency.</li>
<li><code>SYNCH_THREAD_PLACEMENT_NUMA_SPARSE_SMT_PREFER</code>: Combines the sparse distribution strategy across NUMA nodes with a preference for SMT. This policy spreads threads across NUMA nodes to avoid contention, while preferring to fill SMT slots within each core before moving to the next. It aims to strike a balance between improving memory bandwidth and leveraging SMT for higher processing efficiency and reduced contention on shared variables.</li>
<li><code>SYNCH_THREAD_PLACEMENT_DEFAULT</code>: By default the thread placement policy is se to <code>SYNCH_THREAD_PLACEMENT_DEFAULT</code>. Currently, <code>SYNCH_THREAD_PLACEMENT_DEFAULT</code> is equal to <code>SYNCH_THREAD_PLACEMENT_NUMA_SPARSE_SMT_PREFER</code>. <dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">policy</td><td>The thread placement policy to be set. </td></tr>
  </table>
  </dd>
</dl>
</li>
</ul>

</div>
</div>
<a id="a12ae650a6b6b149c2575391e1f12efc5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a12ae650a6b6b149c2575391e1f12efc5">&#9670;&nbsp;</a></span>synchGetThreadPlacementPolicy()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">uint32_t synchGetThreadPlacementPolicy </td>
          <td>(</td>
          <td class="paramtype">void&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Retrieves the current thread placement policy for the machine's processors. This function returns the policy setting that determines how threads are distributed across the processing cores of the machine. The possible return values correspond to the thread placement policies that could be returned are the following: </p>
<ul>
<li><code>SYNCH_THREAD_PLACEMENT_FLAT</code>: Threads are distributed in a round-robin fashion across all processing cores.</li>
<li><code>SYNCH_THREAD_PLACEMENT_NUMA_SPARSE</code>: Optimizes thread placement for systems with Non-Uniform Memory Access (NUMA) by spreading threads sparsely across NUMA nodes, potentially improving memory bandwidth and improving cache utilization.</li>
<li><code>SYNCH_THREAD_PLACEMENT_NUMA_DENSE</code>: Places threads within the smallest number of NUMA nodes before spreading them to other nodes, which can improve memory locality and may reduce contention on shared variables.</li>
<li><code>SYNCH_THREAD_PLACEMENT_NUMA_DENSE_SMT_PREFER</code>: Similar to <code>SYNCH_THREAD_PLACEMENT_NUMA_DENSE</code>, but with a preference for utilizing Simultaneous Multithreading (SMT) capabilities within NUMA nodes to maximize processing efficiency.</li>
<li><code>SYNCH_THREAD_PLACEMENT_NUMA_SPARSE_SMT_PREFER</code>: Combines the sparse distribution strategy across NUMA nodes with a preference for SMT. This policy spreads threads across NUMA nodes to avoid contention, while preferring to fill SMT slots within each core before moving to the next. It aims to strike a balance between improving memory bandwidth and leveraging SMT for higher processing efficiency and reduced contention on shared variables.</li>
<li><code>SYNCH_THREAD_PLACEMENT_DEFAULT</code>: By default the thread placement policy is se to <code>SYNCH_THREAD_PLACEMENT_DEFAULT</code>. Currently, <code>SYNCH_THREAD_PLACEMENT_DEFAULT</code> is equal to <code>SYNCH_THREAD_PLACEMENT_NUMA_SPARSE_SMT_PREFER</code>. </li>
</ul>

</div>
</div>
<a id="a3de1163861672aea5b005f27534c6392"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3de1163861672aea5b005f27534c6392">&#9670;&nbsp;</a></span>synchThreadPin()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int synchThreadPin </td>
          <td>(</td>
          <td class="paramtype">int32_t&#160;</td>
          <td class="paramname"><em>cpu_id</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function sets the CPU affinity of the running thread to cpu_id, where cpu_id should be a unique integer in {0, ..., N-1}, where N is the amount of available processing cores. </p>

</div>
</div>
<a id="af83962f77edd1b750d54c264399ed3c2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af83962f77edd1b750d54c264399ed3c2">&#9670;&nbsp;</a></span>synchPreferredNumaNodeOfThread()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">uint32_t synchPreferredNumaNodeOfThread </td>
          <td>(</td>
          <td class="paramtype">uint32_t&#160;</td>
          <td class="paramname"><em>pid</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a1d09340006207505a5d09fd62f1db266"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1d09340006207505a5d09fd62f1db266">&#9670;&nbsp;</a></span>synchGetThreadId()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">int32_t synchGetThreadId </td>
          <td>(</td>
          <td class="paramtype">void&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>This function returns the id of the running thread (posix or fiber). More specifically, it returns a unique integer in {0, ..., N-1}, where N is the amount of the running threads. For example, if 3 Posix threads are running, and 4 fiber threads are running inside each Posix thread, this function will return an integer in the interval of {0, ...., 11}. </p>

</div>
</div>
<a id="a578692aef02cdeda1bdede23934faa2c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a578692aef02cdeda1bdede23934faa2c">&#9670;&nbsp;</a></span>synchGetPreferredNumaNode()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">int32_t synchGetPreferredNumaNode </td>
          <td>(</td>
          <td class="paramtype">void&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="add65bdc6f8950666dbe2e17fbc850b66"></a>
<h2 class="memtitle"><span class="permalink"><a href="#add65bdc6f8950666dbe2e17fbc850b66">&#9670;&nbsp;</a></span>synchGetPosixThreadId()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">int32_t synchGetPosixThreadId </td>
          <td>(</td>
          <td class="paramtype">void&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>This fuction returns the id of the current posix thread. This function should return an identical value for any fiber running in the same posix thread. </p>

</div>
</div>
<a id="aa340fc67201baff160e5167b063cb02e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa340fc67201baff160e5167b063cb02e">&#9670;&nbsp;</a></span>synchGetPreferredCore()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">int32_t synchGetPreferredCore </td>
          <td>(</td>
          <td class="paramtype">void&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>This function returns the core-id of the current posix thread or fiber. The core-id is a unique integer in {0, ..., N-1}, where N is the amount of available processing cores. </p>

</div>
</div>
<a id="a4f83100fe2cf41ab6047cd8b5fce517e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4f83100fe2cf41ab6047cd8b5fce517e">&#9670;&nbsp;</a></span>synchPreferredCoreOfThread()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">uint32_t synchPreferredCoreOfThread </td>
          <td>(</td>
          <td class="paramtype">uint32_t&#160;</td>
          <td class="paramname"><em>pid</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>This function returns the core-id of the posix thread or fiber with id equal to pid. The core-id is a unique integer in {0, ..., N-1}, where N is the amount of available processing cores. </p>

</div>
</div>
<a id="a02d99105ff01612887e1a97527006a82"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a02d99105ff01612887e1a97527006a82">&#9670;&nbsp;</a></span>synchGetNCores()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">uint32_t synchGetNCores </td>
          <td>(</td>
          <td class="paramtype">void&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>This function returns the number of system's processing cores. </p>

</div>
</div>
<a id="a8e0619760c0a532a8b262fb529486a63"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8e0619760c0a532a8b262fb529486a63">&#9670;&nbsp;</a></span>synchResched()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void synchResched </td>
          <td>(</td>
          <td class="paramtype">void&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>In case that this function is called by a posix thread, it hints OS to give the CPU to some other thread. In case that this function is called by a fiber, it gives the CPU control to the next fiber (if any) running in the same posix thread. </p>

</div>
</div>
<a id="a1100af5666ae597a80ec8aeb6e8e7a92"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1100af5666ae597a80ec8aeb6e8e7a92">&#9670;&nbsp;</a></span>synchIsSystemOversubscribed()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool synchIsSystemOversubscribed </td>
          <td>(</td>
          <td class="paramtype">void&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>This function returns true if the number of spawned threads is greater than the number of system's available processing cores; otherwise, this function returns false. </p>

</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1
</small></address>
</body>
</html>
